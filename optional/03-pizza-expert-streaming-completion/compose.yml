# docker compose up --build --no-log-prefix
services:
  chat-stream:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      TERM: xterm-256color
    stdin_open: true   # docker run -i
    tty: true          # docker run -t
    restart: unless-stopped
    models:
      chat-model:
        endpoint_var: MODEL_RUNNER_BASE_URL
        model_var: MODEL_RUNNER_LLM_CHAT
          
models:
  chat-model:
    model: ai/qwen2.5:1.5B-F16   
